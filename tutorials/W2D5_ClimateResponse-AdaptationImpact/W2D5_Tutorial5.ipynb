{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myt07YFyNgmw"
   },
   "source": [
    "# Tutorial 5:  Testing generalization to new scenarios\n",
    "\n",
    "**Week 2, Day 5: AI and Climate Change**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__  Deepak Mewada, Grace Lindsay\n",
    "__Content reviewers:__ Name Surname, Name Surname\n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname\n",
    "\n",
    "__Production editors:__ Name Surname, Name Surname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDQc1jnoNWcp"
   },
   "source": [
    "___\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 20 minutes*\n",
    "\n",
    "In this tutorial, we will...\n",
    "* Learn about the a different type of out-of-distribution test of our model\n",
    "* Evaluate the model's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlndBdbV5iJF",
    "outputId": "f38fe3d1-ec27-4e2d-ac00-511bec39fa8a"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "\n",
    "## Uncomment the code below to test your function\n",
    "\n",
    "#from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "\n",
    "print(\"If you want to download the slides: 'Link to the slides'\")\n",
    "      # Example: https://osf.io/download/{link_id}/\n",
    "\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "id": "Vtq0OyoRNPcc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idhJGLcxoi_w"
   },
   "source": [
    "<details>\n",
    "<summary> <font color='LightGray'>Click here for overview of this section  </font></summary>\n",
    "\n",
    "1. **Gadget (optional)**: install and import feedback gadget - not relevant for cliamtematch\n",
    "2. **Import cell (required)**: imports all libraries you use in the tutorial\n",
    "3. **Hidden Figure settings cell (optional)**: sets up the plotting style (copy exactly).\n",
    "4. **Hidden Plotting functions cell (optional)**: should contain all functions used to create plots throughout the tutorial (so students don't waste time looking at boilerplate matplotlib but can here if they wish to). Please use only matplotlib for plotting for consistency.\n",
    "5. **Hidden Data retrieval (optional)**: set up the data retrieval needed for the tutorial.\n",
    "6. **Hidden Helper functions cell (optional)**: This should contain functions that students have previously used or that are very simple. Any helper functions that are being used for the first time and are important should be placed directly above the relevant text or exercise (see Tutorial 1.1 for an example).\n",
    "7. **set random seed (with/out pytorch) and set GPU/CPU (optional)**: several cells that set the seed for repeatability and set the GPU for computations  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwsl6-KNNPcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @title Import necessary libraries:\n",
    "\n",
    "import matplotlib.pyplot as plt    # For plotting graphs\n",
    "import pandas as pd                 # For data manipulation\n",
    "# # Import specific machine learning models and tools\n",
    "from sklearn.model_selection import train_test_split      # For splitting dataset into train and test sets\n",
    "from sklearn.ensemble import RandomForestRegressor        # For Random Forest Regression\n",
    "from sklearn.tree import DecisionTreeRegressor            # For Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNqEz5P8j2Q-"
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a `ModuleNotFoundError: No module named 'library name` error , please run `pip install 'library name` to install the required module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRSlfJrugBkf"
   },
   "outputs": [],
   "source": [
    "# @title Helper functions { display-mode: \"form\" }\n",
    "\n",
    "# If any helper functions you want to hide for clarity (that has been seen before\n",
    "# or is simple/uniformative), add here\n",
    "# If helper code depends on libraries that aren't used elsewhere,\n",
    "# import those libaries here, rather than in the main import cell\n",
    "\n",
    "\n",
    "# Load and Prepare the Data\n",
    "url_Climatebench_train_val = \"https://osf.io/y2pq7/download\"  # Dataset URL\n",
    "training_data = pd.read_csv(url_Climatebench_train_val)  # Load the training data from the provided URL\n",
    "training_data.pop('scenario')  # Drop the 'scenario' column as it's just a label and won't be passed into the model\n",
    "target = training_data.pop('tas_FINAL')  # Extract the target variable 'tas_FINAL' which we aim to predict\n",
    "\n",
    "url_spatial_test_data = \"https://osf.io/7tr49/download\" # location of test data\n",
    "spatial_test_data = pd.read_csv(url_spatial_test_data)  # Load spatial test data from the provided URL\n",
    "spatial_test_data.pop('scenario')  #we will drop the `scenario` column from the data as it is just a label, but will not be passed into the model.\n",
    "spatial_test_target = spatial_test_data.pop('tas_FINAL')  # Extract the target variable 'tas_FINAL'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, target, test_size=0.2, random_state=1)\n",
    "\n",
    "# Training the model on the training data\n",
    "rf_regressor = RandomForestRegressor(random_state=42,n_estimators=80,max_depth=50)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "spatial_test_score = rf_regressor.score(spatial_test_data,spatial_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy1MFnohgBkf",
    "outputId": "53de1b32-3381-4f86-acd2-b992a9609883"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed { display-mode: \"form\" }\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# E.g., for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "set_seed(seed=2024)  # change 2023 with any number you like\n",
    "# Set a global seed value for reproducibility\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfDM4UK2ZgrJ"
   },
   "source": [
    "---\n",
    "# **Section 1:Test generalization to held-out emissions scenario**\n",
    "---\n",
    "in this tutorial we will:\n",
    "* Test the modelâ€™s ability on a new type of out-of-distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581,
     "referenced_widgets": [
      "ce3c52bcec184979b768d8d7f35b785b",
      "5932f7bbe8864ce6bc6657f4eff4451f",
      "05aafe4131a14326ad2d835644586e5f",
      "6e4c783c51bc4bafb351b038ea24e934",
      "f55cc4bcbc2440fab7f366a74736b1fb",
      "d1928cd41b5e4dcf8316a88d08071b12"
     ]
    },
    "id": "b3qoqCYHbETG",
    "outputId": "b22b5306-b345-40d0-8825-0885f730dbed"
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, IFrame, YouTubeVideo\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"\", width=854, height=480, fs=1)\n",
    "  print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  video = YouTubeVideo(id=\"\", width=854, height=480, fs=1, rel=0)\n",
    "  print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSCs0c2Lkh-u"
   },
   "source": [
    "Video Summary :  \n",
    "* Discuss how we previously tested generalization to unseen region  \n",
    "* Stress that the real utility of these emulators is the ability to run new scenarios   \n",
    "* Now we will see if the model generalizes to data from a new scenario\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY2pRdBMkh-u"
   },
   "source": [
    "## Section 1.1: Load the new testing (Scenario) data\n",
    "Load the new dataset and print it. As you can see, the scenario for all of these datapoints is ssp245. This scenario was not included in our initial data set. According to the scenario descriptions included in the table in Tutorial 1, ssp245 represent a \"medium forcing future scenario\". The lat/lon locations are the same as the initial dataset (blue box region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rt6Sa8Kjkh-u",
    "outputId": "9c696c9d-daad-48e7-94a4-80e7f4cb8a74"
   },
   "outputs": [],
   "source": [
    "url_scenario_test_data = \"https://osf.io/pkbwx/download\"  # Dataset URL\n",
    "scenario_test_data = pd.read_csv(url_scenario_test_data)  # Load scenario test data from the provided URL\n",
    "scenario_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cutnjPxiZh4M"
   },
   "source": [
    "Now we will prepare the data to be fed into the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XRuDwQtrZlwO",
    "outputId": "4e69e0a1-ded4-4ebb-bf6d-d84100273222"
   },
   "outputs": [],
   "source": [
    "scenario_test_data.pop('scenario')  # Remove the 'scenario' column from the dataset\n",
    "scenario_test_target = scenario_test_data.pop('tas_FINAL')  # Extract the target variable 'tas_FINAL'\n",
    "scenario_test_data  # Display the prepared scenario test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_gknRZ1kh-u"
   },
   "source": [
    "## Section 1.2: Evaluate the model on this new (scenario) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1xib3Pjkh-v"
   },
   "source": [
    "Now let's evaluate our pre-trained model(`rf_regressor`) to see how well it performs on this new emissions scenario. Use what you know to evaluate the performance and make a scatter plot of predicted vs. true temperature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWFQtDIdvdel"
   },
   "outputs": [],
   "source": [
    "def evaluate_and_plot_scenario_performance(rf_regressor, scenario_test_data, scenario_test_target):\n",
    "    \"\"\"Evaluate the performance of a pre-trained model on a new emissions scenario and create a scatter plot.\n",
    "\n",
    "    Args:\n",
    "        rf_regressor (RandomForestRegressor): Pre-trained Random Forest regressor model.\n",
    "        scenario_test_data (ndarray): Test features for the new emissions scenario.\n",
    "        scenario_test_target (ndarray): Test labels for the new emissions scenario.\n",
    "\n",
    "    Returns:\n",
    "        float: Score of the model on the scenario test data.\n",
    "    \"\"\"\n",
    "    #################################################\n",
    "    ## TODO for students: details of what they should do ##\n",
    "    # Evaluate the performance of the pre-trained model (`rf_regressor`) on the new emissions scenario\n",
    "    # Calculate the score using .score() method and print it out\n",
    "    # Use rf_regressor to predict temperature values for the scenario test data\n",
    "    # Create a scatter plot of predicted vs. true temperature values\n",
    "    # Use plt.scatter() to plot the data points\n",
    "    # Use plt.plot() to plot the diagonal line y=x\n",
    "    # Label the x-axis as 'Predicted Temperatures' and y-axis as 'True Temperatures'\n",
    "    # Fill remove the following line of code once you have completed the exercise:\n",
    "    raise NotImplementedError(\"Student exercise: Implement the evaluation and plotting process.\")\n",
    "    #################################################\n",
    "\n",
    "    # Evaluate the performance of the pre-trained model on the new emissions scenario\n",
    "    scenario_test_score = ...\n",
    "\n",
    "    print(\"Scenario Test Score:\", scenario_test_score)\n",
    "\n",
    "    # Use rf_regressor to predict temperature values for the scenario test data\n",
    "    scenario_test_predicted = ...\n",
    "\n",
    "    # Create a scatter plot of predicted vs. true temperature values\n",
    "    plt.scatter(..., scenario_test_target, color='b')\n",
    "    plt.plot([0, 4], [0, 4], color='r')\n",
    "    plt.xlabel('Predicted Temperatures')\n",
    "    plt.ylabel('True Temperatures')\n",
    "    plt.title('Scatter Plot of Predicted vs. True Temperature Values')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return scenario_test_score\n",
    "\n",
    "# Uncomment the code below to run this cell\n",
    "# scenario_test_score = evaluate_and_plot_scenario_performance(rf_regressor, scenario_test_data, scenario_test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "rdJ09mXpvo0l",
    "outputId": "aeb2341e-2dc3-4302-d36d-1c542ac5ddac"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def evaluate_and_plot_scenario_performance(rf_regressor, scenario_test_data, scenario_test_target):\n",
    "    \"\"\"Evaluate the performance of the pre-trained model on the new emissions scenario\n",
    "    and create a scatter plot of predicted vs. true temperature values.\n",
    "\n",
    "    Args:\n",
    "        rf_regressor (RandomForestRegressor): Pre-trained Random Forest regressor model.\n",
    "        scenario_test_data (ndarray): Test features for the new emissions scenario.\n",
    "        scenario_test_target (ndarray): True temperature values for the new emissions scenario.\n",
    "\n",
    "    Returns:\n",
    "        float: Score of the model on the new emissions scenario.\n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate the model on the new emissions scenario\n",
    "    scenario_test_score = rf_regressor.score(scenario_test_data, scenario_test_target)\n",
    "    print(\"Scenario Test Score:\", scenario_test_score)\n",
    "\n",
    "    # Predict temperature values for the new emissions scenario\n",
    "    scenario_test_predicted = rf_regressor.predict(scenario_test_data)\n",
    "\n",
    "    # Create a scatter plot of predicted vs. true temperature values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(scenario_test_predicted, scenario_test_target, color='b')\n",
    "    plt.plot([min(scenario_test_predicted), max(scenario_test_predicted)], [min(scenario_test_target), max(scenario_test_target)], color='r')\n",
    "    plt.xlabel('Predicted Temperatures')\n",
    "    plt.ylabel('True Temperatures')\n",
    "    plt.title('Scatter Plot of Predicted vs. True Temperature Values for New Emissions Scenario')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return scenario_test_score\n",
    "\n",
    "# Example usage:\n",
    "scenario_test_score = evaluate_and_plot_scenario_performance(rf_regressor, scenario_test_data, scenario_test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDnH3moCkh-v"
   },
   "source": [
    "### Think 5.2 : Performance of the model on new Scenario data\n",
    "\n",
    "1. Again, Have you observed the decrease in score?   \n",
    "2. What do you believe could be the cause of this?   \n",
    "3. What kind of new scenarios might the model perform better for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "HLTa9Oqux0jS",
    "outputId": "a9527f82-968a-4ad3-9c6a-4cbf7c4f7f3c"
   },
   "outputs": [],
   "source": [
    "#to_remove_explanation\n",
    "\n",
    "\"\"\"\n",
    "1. Yes, there appears to be a decrease in score when the model is tested on new scenario data, though it is still well-above 0 suggesting the model has learned something about predicting temperature from emissions.\n",
    "2. The decrease in score could be due to the model's inability to generalize well to new scenarios. It's possible that the model was trained on a specific set of scenarios and may not perform as accurately when presented with new, unseen scenarios. Factors such as differences in data distribution, environmental conditions, or other variables not captured in the training data could contribute to this decrease in performance.\n",
    "3. The model might perform better for new scenarios that are similar to the ones it was trained on. Additionally, if the new scenarios have data distributions and patterns that are more aligned with the training data, the model could potentially perform better. However, it's important to note that the model's performance on new scenarios will ultimately depend on how well it can adapt and generalize to the differences present in the new data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bwSJgqivs2Y"
   },
   "source": [
    "For the sake of clarity let's summarize all the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwgBFM9vuT5L",
    "outputId": "eeca11b3-af1a-4bc2-ba58-ad62b414d278"
   },
   "outputs": [],
   "source": [
    "# @title  { display-mode: \"form\" }\n",
    "# @markdown Run this cell to print the Summary of result\n",
    "#\n",
    "train_score = rf_regressor.score(X_train, y_train)\n",
    "test_score  = rf_regressor.score(X_test, y_test)\n",
    "average_score = (train_score + test_score + spatial_test_score + scenario_test_score) / 4\n",
    "print(f\"\\tTraining Data Score                             : {train_score}\")\n",
    "print(f\"\\tTesting Data Score on same Scenario/Region      : {test_score}\")\n",
    "print(f\"\\tHeld-out Spatial Region Test Score              : {spatial_test_score}\")\n",
    "print(f\"\\tHeld-out Scenario Test Score                    : {scenario_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL5aKZXdIaNq"
   },
   "source": [
    "This shows us that the model does generalize somewhat (i.e. the score is well above zero even in the new regions and th the new scenario). However it does not generalize very well. That is, it does not perform as well on data that differs from the data it was trained on. Ideally we would be able to build a model that inherently learns the complex relationship between emissions scenarios and future temperature. A model that truly learned this relationship would be able to generalize to new scenarios and regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ybZeJ2NKAd1"
   },
   "source": [
    "\n",
    "Do you have any ideas of how to build a better machine learning model to emulate climate models? Many scientists are working on this problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5S4fpfS7343b"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this tutorial, we explored how machine learning models adapt to unfamiliar emissions scenarios. Evaluating model performance on datasets representing different emission scenarios provided insights into the models' capabilities in predicting climate variables under diverse environmental conditions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOr06goiJGmb"
   },
   "source": [
    "---\n",
    "# (Bonus) **Section 2: Try other Regression models**\n",
    "---\n",
    "Only complete this section if you are well-ahead of schedule, or have already completed the final tutorial.\n",
    "\n",
    "Random Forest models are not the only regression models that could be applied to this problem. In this code, we will use scikit-learn to train and evaluate various regression models on the Climate Bench dataset. We will load the data, split it, define models, train them with different settings, and evaluate their performance. We will calculate and print average scores for each model configuration and identify the best-performing model.\n",
    "\n",
    "For more information about the models used here and various other models, you can refer to [scikit-learn.org/stable/supervised_learning.html#supervised-learning](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning).  \n",
    " Note: the cell may take ~2 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEHe9BDeJBfT",
    "outputId": "ecf7c1f8-7ba0-4ed5-9542-31beb27dd83a"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Load datasets\n",
    "train_val_data = pd.read_csv(\"https://osf.io/y2pq7/download\")\n",
    "spatial_test_data = pd.read_csv(\"https://osf.io/7tr49/download\")\n",
    "scenario_test_data = pd.read_csv(\"https://osf.io/pkbwx/download\")\n",
    "\n",
    "# Pop the 'scenario' column from all datasets\n",
    "train_val_data.pop('scenario')\n",
    "spatial_test_data.pop('scenario')\n",
    "scenario_test_data.pop('scenario')\n",
    "\n",
    "# Split train_val_data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_val_data.drop(columns=[\"tas_FINAL\"]),\n",
    "                                                    train_val_data[\"tas_FINAL\"],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "\n",
    "# Define models with different configurations\n",
    "models = {\n",
    "    \"MLP\": [make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "            make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(500, 500, 500), random_state=1, max_iter=1000))],\n",
    "    \"RandomForest\": [make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=100, max_depth=None)),\n",
    "                     make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=50, max_depth=10))],\n",
    "    \"GradientBoosting\": [make_pipeline(StandardScaler(), GradientBoostingRegressor(n_estimators=100, max_depth=3)),\n",
    "                         make_pipeline(StandardScaler(), GradientBoostingRegressor(n_estimators=50, max_depth=2))],\n",
    "    \"BaggingRegressor\": [make_pipeline(StandardScaler(), BaggingRegressor(n_estimators=100)),\n",
    "                         make_pipeline(StandardScaler(), BaggingRegressor(n_estimators=50))],\n",
    "    \"SVR\": [make_pipeline(StandardScaler(), SVR(kernel=\"linear\")),\n",
    "            make_pipeline(StandardScaler(), SVR(kernel=\"rbf\"))],\n",
    "    \"LinearRegression\": [make_pipeline(StandardScaler(), LinearRegression())],\n",
    "    \"Ridge\": [make_pipeline(StandardScaler(), Ridge())],\n",
    "    \"RidgeCV\":[RidgeCV(alphas=[167], cv=5)],\n",
    "    \"Lasso\": [make_pipeline(StandardScaler(), Lasso())],\n",
    "    \"ElasticNet\": [make_pipeline(StandardScaler(), ElasticNet())]\n",
    "}\n",
    "\n",
    "# Train models and calculate score for each configuration\n",
    "results = {}\n",
    "for model_name, model_list in models.items():\n",
    "    model_results = []\n",
    "    for config_num, model in enumerate(model_list):  # Add enumeration for configuration number\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calculate scores\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        spatial_test_score = model.score(spatial_test_data.drop(columns=[\"tas_FINAL\"]), spatial_test_data[\"tas_FINAL\"])\n",
    "        scenario_test_score = model.score(scenario_test_data.drop(columns=[\"tas_FINAL\"]), scenario_test_data[\"tas_FINAL\"])\n",
    "\n",
    "        # Append results\n",
    "        model_results.append({\n",
    "            \"Configuration\": config_num,  # Add configuration number\n",
    "            \"Training Score\": train_score,\n",
    "            \"Testing Score\": test_score,\n",
    "            \"Spatial Test Score\": spatial_test_score,\n",
    "            \"Scenario Test Score\": scenario_test_score\n",
    "        })\n",
    "\n",
    "        # Calculate average score for the model\n",
    "    average_score = sum(sum(result.values()) for result in model_results) / (len(model_results) * 4)\n",
    "\n",
    "    # Store results including average score\n",
    "    results[model_name] = {\"Average Score\": average_score, \"Results\": model_results}\n",
    "\n",
    "# Print results including average score for each model\n",
    "for model_name, model_data in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Average Score: {model_data['Average Score']}\")\n",
    "    print(\"Configuration-wise Average Scores:\")\n",
    "    for result in model_data['Results']:\n",
    "        print(f\"Configuration {result['Configuration']}: \"\n",
    "              f\"Training Score: {result['Training Score']}, \"\n",
    "              f\"Testing Score: {result['Testing Score']}, \"\n",
    "              f\"Spatial Test Score: {result['Spatial Test Score']}, \"\n",
    "              f\"Scenario Test Score: {result['Scenario Test Score']}\")\n",
    "    print()\n",
    "\n",
    "# Find the best model and its average score\n",
    "best_model = max(results, key=lambda x: results[x][\"Average Score\"])\n",
    "best_average_score = results[best_model][\"Average Score\"]\n",
    "\n",
    "# Print the best model and its average score\n",
    "print(f\"Best Model: {best_model}, Average Score: {best_average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDIq02jv7es6"
   },
   "source": [
    " let's plot the result.    \n",
    "Note: This code will plot the actual score for positive average scores and zero for negative average scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "osyOejNO5CZE",
    "outputId": "9d70f7cf-cd11-4d5a-d8c6-d2903e01798c"
   },
   "outputs": [],
   "source": [
    "# @title  { display-mode: \"form\" }\n",
    "# @markdown Run this cell to see the plot of results!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract model names and average scores from results\n",
    "model_names = list(results.keys())\n",
    "average_scores = [results[model_name][\"Average Score\"] for model_name in model_names]\n",
    "\n",
    "# Adjust scores to plot zero for negative scores\n",
    "adjusted_scores = [score if score > 0 else 0 for score in average_scores]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_names, adjusted_scores, color=['skyblue' if score > 0 else 'lightgray' for score in average_scores])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Average Score')\n",
    "plt.title('Average Score of Different Regression Models')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8MVfXNSAFWc"
   },
   "source": [
    "This quick sweep of models suggests Random Forest is a good choice, but recall that most of these models have hyperparameters. Varying these hyperparameters may lead to different results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0Ujuy7zDcfg"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "                                Congratulations! You have reached the end of the  tutorial.   \n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05aafe4131a14326ad2d835644586e5f": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_d1928cd41b5e4dcf8316a88d08071b12",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Video available at https://www.bilibili.com/video/\n"
        ]
       },
       {
        "data": {
         "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://player.bilibili.com/player.html?bvid=&page=1?fs=1\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ",
         "text/plain": "<__main__.BiliVideo at 0x7938bce94550>"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "5932f7bbe8864ce6bc6657f4eff4451f": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_f55cc4bcbc2440fab7f366a74736b1fb",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Video available at https://youtube.com/watch?v=\n"
        ]
       },
       {
        "data": {
         "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ",
         "text/plain": "<IPython.lib.display.YouTubeVideo at 0x793885ba5630>"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "6e4c783c51bc4bafb351b038ea24e934": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce3c52bcec184979b768d8d7f35b785b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TabModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TabModel",
      "_titles": {
       "0": "Youtube",
       "1": "Bilibili"
      },
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TabView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5932f7bbe8864ce6bc6657f4eff4451f",
       "IPY_MODEL_05aafe4131a14326ad2d835644586e5f"
      ],
      "layout": "IPY_MODEL_6e4c783c51bc4bafb351b038ea24e934",
      "selected_index": 0
     }
    },
    "d1928cd41b5e4dcf8316a88d08071b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f55cc4bcbc2440fab7f366a74736b1fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
