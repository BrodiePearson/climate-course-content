{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myt07YFyNgmw"
   },
   "source": [
    "# Tutorial 3:  Testing Model Generalization\n",
    "\n",
    "**Week 2, Day 5: AI and Climate Change**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__  Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ Jenna Pearson\n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDQc1jnoNWcp"
   },
   "source": [
    "___\n",
    "\n",
    "# Tutorial Objectives\n",
    "\n",
    "*Estimated timing of tutorial: 25 minutes*\n",
    "\n",
    "In this tutorial, we will...\n",
    "* Understand the problem of overfitting\n",
    "* Understand generalization\n",
    "* Learn to split data into train and test data\n",
    "* Evaluate trained models on held-out test data\n",
    "* Think about the relationship between model capacity and overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlndBdbV5iJF",
    "outputId": "25084ef3-8417-4a5f-8ebf-0dfec2d90dfc"
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in all tutorials today\n",
    "\n",
    "\n",
    "## Uncomment the code below to test your function\n",
    "\n",
    "#from IPython.display import IFrame\n",
    "#link_id = \"<YOUR_LINK_ID_HERE>\"\n",
    "\n",
    "print(\"If you want to download the slides: 'Link to the slides'\")\n",
    "      # Example: https://osf.io/download/{link_id}/\n",
    "\n",
    "#IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{link_id}/?direct%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "id": "Vtq0OyoRNPcc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwsl6-KNNPcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @title Import necessary libraries:\n",
    "\n",
    "import pandas as pd                 # For data manipulation\n",
    "from sklearn.model_selection import train_test_split      # For splitting dataset into train and test sets\n",
    "from sklearn.ensemble import RandomForestRegressor        # For Random Forest Regression\n",
    "from sklearn.tree import DecisionTreeRegressor            # For Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNqEz5P8j2Q-"
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a `ModuleNotFoundError: No module named 'library name` error , please run `pip install 'library name` to install the required module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy1MFnohgBkf",
    "outputId": "5b59e43e-acc5-4670-f6d2-12645a585e43"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed { display-mode: \"form\" }\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# E.g., for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "set_seed(seed=2024)  # change 2023 with any number you like\n",
    "# Set a global seed value for reproducibility\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua8XZtQ4_d7b"
   },
   "source": [
    "---\n",
    "# **Section 1: Model generalization**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581,
     "referenced_widgets": [
      "82c7600a266d420eb74deb693697c2d5",
      "666b371218354c83b8f01cb2d81a7c00",
      "046054f25dad4c869bd2947642ccd869",
      "16c9961b858a4804b3ad7bdccb57431e",
      "3ac9ce4eed7a4285ae7a367b9923568e",
      "b9b0602a10f9471f8478339ce536ce1b"
     ]
    },
    "id": "ePKqT65QBJSC",
    "outputId": "477d5987-bf40-4a27-9fbc-449e8aec8d9c"
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name  # put in the title of your video\n",
    "# note the libraries are imported here on purpose\n",
    "\n",
    "###@@@ for konstanine. a question, why isn't this above in the list of cells?\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# curriculum or production team will provide these ids\n",
    "video_ids = [('Youtube', '<video_id_1>'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siDJE1JScMHU"
   },
   "source": [
    "As discussed in the video, machine learning models can *overfit*. This means they essentially memorize the data points they were trained on. This makes them perform very well on those data points, but when they are presented with data they weren't trained on their predictions are not very good. Therefore, we need to evaluate our models according to how well they perform on data they weren't trained on.\n",
    "\n",
    "To do this, we will split the data into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate how well the model performs on unseen data. This helps us ensure that our model can generalize well to new data and avoid overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l-FpQGjdMvm"
   },
   "source": [
    "## Section 1.1 : Load and Prepare the Data\n",
    "\n",
    "As we've learned in the previous tutorial, here we load our dataset and prepare it by removing unnecessary columns and extracting the target variable 'tas_FINAL', representing temperature anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "go_ea6wUdysz"
   },
   "outputs": [],
   "source": [
    "# Load and Prepare the Data\n",
    "url_Climatebench_train_val = \"https://osf.io/y2pq7/download\" # Dataset URL\n",
    "training_data = pd.read_csv(url_Climatebench_train_val)  # Load the training data from the provided URL\n",
    "training_data.pop('scenario')  #we will drop the `scenario` column from the data as it is just a label, but will not be passed into the model.\n",
    "target = training_data.pop('tas_FINAL')  # Extract the target variable 'tas_FINAL' which we aim to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLdPvfbwA4jn"
   },
   "source": [
    "## Section 1.2: Data Splitting for Training and Testing\n",
    "\n",
    "Now, our primary objective is to prepare our dataset for model training and evaluation. To achieve this, we'll utilize the `train_test_split` function from Scikit-learn, which conveniently splits our dataset into training and testing subsets.\n",
    "\n",
    "To facilitate this process, we've imported the essential `train_test_split` function from Scikit-learn earlier in the code:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split      \n",
    "```\n",
    "\n",
    "Our strategy involves randomly allocating 20% of the data for testing purposes, while reserving the remaining 80% for model training. This ensures that our model is evaluated on unseen data, which is crucial for assessing its real-world performance.\n",
    "\n",
    "With this function ready to use, let's seamlessly proceed to split our dataset and go ahead on the journey of model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNuku87mOp5N"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_data, target, test_size=0.2, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_RqSUBkuNev"
   },
   "source": [
    "We now have separated the input features (now called `X`) and the target variable (now called `y`) into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYgCCj6gBJhO"
   },
   "source": [
    "## Section 1.3 : Train a decision tree model on the training data and evaluate it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "sWroxkvmCRcR",
    "outputId": "bc1263db-eb4c-438e-9129-d480edadf75c"
   },
   "outputs": [],
   "source": [
    "# Training the model on the training data\n",
    "dt_regressor = DecisionTreeRegressor(random_state=random_state,max_depth=20)\n",
    "dt_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGztBoOXCesU"
   },
   "source": [
    "Now we will evaluate the model on both the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cmPJpgSClvz",
    "outputId": "7fb882ba-f5c8-40f8-c9ac-13cdd3003aca"
   },
   "outputs": [],
   "source": [
    "print('Performance on training data :', dt_regressor.score(X_train, y_train))\n",
    "print('Performance on test data     :', dt_regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPbU2D25FX30"
   },
   "source": [
    "We can see here that our model is overfitting: it is performing much better on the data it was trained on than on held-out test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ldmvp28iEuRh"
   },
   "source": [
    "## Section 1.4 : Train a random forest model on the testing data and evaluate it\n",
    "\n",
    "Use what you know to train a random forest model on the training data and evaluate it on both the training and test data.\n",
    "We have already imported `RandomForestRegressor` in Setup section via\n",
    "```\n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbS9mZtWkvuK"
   },
   "outputs": [],
   "source": [
    "def train_random_forest_model(X_train, y_train, X_test, y_test, random_state):\n",
    "    \"\"\"Train a Random Forest model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training labels.\n",
    "        X_test (ndarray): Test features.\n",
    "        y_test (ndarray): Test labels.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        RandomForestRegressor: Trained Random Forest regressor model.\n",
    "    \"\"\"\n",
    "    #################################################\n",
    "    ## TODO for students: details of what they should do ##\n",
    "    # Implement training a RandomForestRegressor model using X_train and y_train\n",
    "    # Then, evaluate its performance on both training and test data using .score() method\n",
    "    # Print out the performance on training and test data\n",
    "    # Fill remove the following line of code one you have completed the exercise:\n",
    "    raise NotImplementedError(\"Student exercise: Implement the training and evaluation process.\")\n",
    "    #################################################\n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_regressor = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "    #fill in the code\n",
    "    #rf_regressor.fit(...., ...)\n",
    "\n",
    "    print('Performance on training data:', rf_regressor.score(X_train, y_train))\n",
    "    print('Performance on test data:', rf_regressor.score(X_test, y_test))\n",
    "\n",
    "    #The difference between performance on training and test data is less for the random forest model\n",
    "\n",
    "    return rf_regressor\n",
    "\n",
    "# uncomment this to call the function:\n",
    "# rf_model = train_random_forest_model(X_train, y_train, X_test, y_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxifZbjzrlQ5",
    "outputId": "5f0a66b0-9ef7-4b8c-e2c9-ddaa8509e05d"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def train_random_forest_model(X_train, y_train, X_test, y_test, random_state):\n",
    "    \"\"\"Train a Random Forest model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training labels.\n",
    "        X_test (ndarray): Test features.\n",
    "        y_test (ndarray): Test labels.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        RandomForestRegressor: Trained Random Forest regressor model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_regressor = RandomForestRegressor(random_state=random_state)\n",
    "    rf_regressor.fit(X_train, y_train)\n",
    "    print('Performance on training data :', rf_regressor.score(X_train, y_train))\n",
    "    print('Performance on test data     :', rf_regressor.score(X_test, y_test))\n",
    "\n",
    "    #The difference between performance on training and test data is less for the random forest model\n",
    "\n",
    "    return rf_regressor\n",
    "\n",
    "# uncomment this to call the function:\n",
    "rf_model = train_random_forest_model(X_train, y_train, X_test, y_test, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNvkM8PYem67"
   },
   "source": [
    "### Think 3.3 : Overfitting - Decision tree vs Random Forest\n",
    "1. Does the random forest model overfit less than a single decision tree?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "YqBbuUXbsC5c",
    "outputId": "0bac62ec-6e13-449b-c339-e239e9401860"
   },
   "outputs": [],
   "source": [
    "#to_remove_explanation\n",
    "\n",
    "\"\"\"\n",
    "The difference between performance on training and test data is less for the random forest model therefore it overfits less.\n",
    "This is consistent with what we learned about the benefit of using ensemble models. ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSz7m4ybQtnC"
   },
   "source": [
    "## Section 1.5 : Explore parameters of the random forest model\n",
    "\n",
    "In the previous tutorial we saw how we can control the depth of a single decision tree.   \n",
    "We can also control the depth of the decision trees used in our random forest model by passing in a `max_depth` argument. We can also control the number of trees in the random forest model by setting `n_estimator`.\n",
    "\n",
    "Intuitively, these variables control the *capacity* of the model. Capacity loosely refers to the number of trainable parameters in the model. The more trees and the deeper they are, the more free parameters the model has to capture the training data. If the model has too low of capacity, it won't be powerful enough to capture complex relationships between the input features and the target variable. If it has too many parameters that it can move around, however, it may end up memorizing every single training point and therefore overfit.\n",
    "\n",
    "Use the sliders below to experiment with different values of `n_estimator` and `max_depth` and see how they impact performance on training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTAv3t1Azi83"
   },
   "source": [
    "### Interactive Demo 3.1:  Peformance of Random Forest\n",
    "In this activity, you can adjust the sliders for `n_estimators` and `max_depth` to observe their effect on model performance:\n",
    "\n",
    "* `n_estimators`: Controls the number of trees in the Random Forest.   \n",
    "* `max_depth`: Sets the maximum depth of each tree.  \n",
    "After adjusting the sliders, the code fits a new Random Forest model and prints the training and testing scores, showing how changes in these parameters impact model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VO76KJXXQ4OY",
    "outputId": "bba7e4e2-c317-4ffe-d3ca-34210ba47e0f"
   },
   "outputs": [],
   "source": [
    "# @title Use the slider to change the values of 'n_estimators' and 'max_depth' and observe the effect on performance. { run: \"auto\", form-width: \"50%\", display-mode: \"form\" }\n",
    "# @markdown Make sure you execute this cell to enable the widget!\n",
    "\n",
    "\n",
    "n_estimators = 30 # @param {type:\"slider\", min:10, max:100, step:10}\n",
    "max_depth = 20 # @param {type:\"slider\", min:5, max:50, step:5}\n",
    "rf_regressor = RandomForestRegressor(n_estimators=50, max_depth=10)  # Change this and check the score\n",
    "\n",
    "\n",
    "rf_regressor.fit(X_train, y_train) # Train the model on the training data\n",
    "# Print scores\n",
    "print(f\"\\tn_estimators = {n_estimators}, max_depth = {max_depth}:\")\n",
    "print(f\"\\n\\tTraining Score : {rf_regressor.score(X_train, y_train)}\")\n",
    "print(f\"\\tTesting Score  : {rf_regressor.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JhT6eg0QM2x"
   },
   "source": [
    "### Interactive Demo 3.1 Discussion\n",
    "\n",
    "1. Did you observe any trends in how the performance changes?  \n",
    "2. Try to explain in you own words the concepts of capacity and overfitting and how they relate.\n",
    "3. In addition to model capacity, what else could be changed to prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "tizaDDH3hbA0",
    "outputId": "406779f5-943f-4efb-edda-b81d4bdbe5d8"
   },
   "outputs": [],
   "source": [
    "#to_remove_explanation\n",
    "\n",
    "# airtable\n",
    "# relevant_variable_name: text\n",
    "\n",
    "\"\"\"\n",
    "1. Observations: Adjusting `n_estimators` and `max_depth` may cause fluctuations in model performance. Increasing `n_estimators` initially improves performance, but too many trees may lead to overfitting. Similarly, increasing `max_depth` initially enhances performance by capturing complex patterns, but excessively deep trees may result in overfitting.\n",
    "\n",
    "2. Capacity and Overfitting: Capacity refers to a model's ability to capture complex patterns, while overfitting occurs when a model learns noise instead of true patterns. Increasing capacity, like using more trees or deeper trees, can lead to overfitting.\n",
    "\n",
    "3. Preventing Overfitting: Apart from adjusting model capacity, we could also consider training on a larger dataset. Machine learning techniques like regularization techniques, cross-validation, feature selection, and ensemble methods help prevent overfitting. These approaches ensure the model generalizes well to unseen data by balancing complexity and performance.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7VAbXQxYiNP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "In this tutorial, we delved into the importance of training and testing sets in constructing robust machine learning models. Understanding the concept of overfitting and the necessity of using separate test sets for model assessment were pivotal. Through practical exercises, we acquired hands-on proficiency in data partitioning, model training, and performance evaluation.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SpKyVbrKzHe"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "                                Congratulations! You have reached the end of the  tutorial.   \n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
