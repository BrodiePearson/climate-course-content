{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myt07YFyNgmw"
   },
   "source": [
    "# Tutorial 1:  ClimateBench Dataset and How Machine Learning Can Help\n",
    "\n",
    "**Week 2, Day 5: AI and Climate Change**\n",
    "\n",
    "**By Climatematch Academy**\n",
    "\n",
    "__Content creators:__  Deepak Mewada, Grace Lindsay\n",
    "\n",
    "__Content reviewers:__ Jenna Pearson\n",
    "\n",
    "__Content editors:__ Name Surname, Name Surname\n",
    "\n",
    "__Production editors:__ Konstantine Tsafatinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "kDQc1jnoNWcp",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "___\n",
    "\n",
    "# Tutorial Objectives\n",
    "*Estimated timing of tutorial: 25 minutes*\n",
    "\n",
    "Today, we have total 6 short tutorials.  In Tutorial 1, we delve into the fundamentals, including discussions on climate model emulators and the ClimateBench dataset. We gain insights into Earth System Models (ESMs) and Shared Socioeconomic Pathways (SSPs), alongside practical visualization techniques for ClimateBench features. Tutorial 2 expands on these foundations, exploring decision trees, hyperparameters, and random forest models. We learn to evaluate regression models, focusing on the coefficient of determination (R^2), and gain hands-on experience implementing models using scikit-learn. Tutorial 3 shifts focus to mitigating overfitting in machine learning models. Here, we learn the importance of model generalization and acquire practical skills for splitting data into training and test sets. In Tutorial 4, we refine our understanding of model robustness, with emphasis on within-distribution generalization and testing model performance on similar data. Tutorial 5 challenges us to test our models on various types of out-of-distribution data, while also exploring the role of climate model emulators in climate science research. Finally, Tutorial 6 concludes the series by discussing practical applications of AI and machine learning in addressing climate change-related challenges, and introducing available resources and tools in the field of climate change AI.\n",
    "\n",
    "In this tutorial 1, we will...\n",
    "* Learn about the basics of data science and machine learning\n",
    "* Define “climate model emulators”\n",
    "* Introduce the ClimateBench dataset\n",
    "* Visualize features from this dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "wlndBdbV5iJF",
    "outputId": "620f5d20-13f5-4fe3-a099-9de85e479b16",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import IFrame\n",
    "\n",
    "link_id = \"4k3jd\"\n",
    "\n",
    "download_link = f\"https://osf.io/download/{link_id}/\"\n",
    "render_link = f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/{link_id}/?direct%26mode=render%26action=download%26mode=render\"\n",
    "# @markdown\n",
    "out = widgets.Output()\n",
    "with out:\n",
    "    print(f\"If you want to download the slides: {download_link}\")\n",
    "    display(IFrame(src=f\"{render_link}\", width=730, height=410))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {},
    "id": "Vtq0OyoRNPcc"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwsl6-KNNPcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @title Import necessary libraries:\n",
    "\n",
    "import matplotlib.pyplot as plt    # For plotting graphs\n",
    "import pandas as pd                 # For data manipulation\n",
    "import seaborn as sns               # For advanced visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNqEz5P8j2Q-"
   },
   "source": [
    "<details>\n",
    "<summary> <font color='Red'>Click here if you are running on local machine or you encounter any error while importing   </font></summary>\n",
    "Please note that if you are running this code on a local machine and encounter an error while importing a library, make sure to install the library via pip. For example, if you receive a `ModuleNotFoundError: No module named 'library name` error , please run `pip install 'library name` to install the required module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy1MFnohgBkf",
    "outputId": "f575d1bc-b4f5-4692-f22c-f2756e22c3c0"
   },
   "outputs": [],
   "source": [
    "# @title Set random seed { display-mode: \"form\" }\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# E.g., for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=None):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "set_seed(seed=2024)  # change 2023 with any number you like\n",
    "# Set a global seed value for reproducibility\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nULavCfq4o07"
   },
   "source": [
    "---\n",
    "# **Section 1: ClimateBench Dataset and How Machine Learning Can Help**\n",
    "---\n",
    "Section Objective:\n",
    "* Understand how machine learning can be helpful generally\n",
    "* Understand the climate model data we will be working with\n",
    "* Understand the concept of a climate model emulator\n",
    "* Learn how to explore the dataset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Video 1: Video 1 Name  # put in the title of your video\n",
    "# note the libraries are imported here on purpose\n",
    "\n",
    "###@@@ for konstanine. a question, why isn't this above in the list of cells?\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import IFrame\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "class PlayVideo(IFrame):\n",
    "  def __init__(self, id, source, page=1, width=400, height=300, **kwargs):\n",
    "    self.id = id\n",
    "    if source == 'Bilibili':\n",
    "      src = f'https://player.bilibili.com/player.html?bvid={id}&page={page}'\n",
    "    elif source == 'Osf':\n",
    "      src = f'https://mfr.ca-1.osf.io/render?url=https://osf.io/download/{id}/?direct%26mode=render'\n",
    "    super(PlayVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "\n",
    "def display_videos(video_ids, W=400, H=300, fs=1):\n",
    "  tab_contents = []\n",
    "  for i, video_id in enumerate(video_ids):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "      if video_ids[i][0] == 'Youtube':\n",
    "        video = YouTubeVideo(id=video_ids[i][1], width=W,\n",
    "                             height=H, fs=fs, rel=0)\n",
    "        print(f'Video available at https://youtube.com/watch?v={video.id}')\n",
    "      else:\n",
    "        video = PlayVideo(id=video_ids[i][1], source=video_ids[i][0], width=W,\n",
    "                          height=H, fs=fs, autoplay=False)\n",
    "        if video_ids[i][0] == 'Bilibili':\n",
    "          print(f'Video available at https://www.bilibili.com/video/{video.id}')\n",
    "        elif video_ids[i][0] == 'Osf':\n",
    "          print(f'Video available at https://osf.io/{video.id}')\n",
    "      display(video)\n",
    "    tab_contents.append(out)\n",
    "  return tab_contents\n",
    "\n",
    "# curriculum or production team will provide these ids\n",
    "video_ids = [('Youtube', 'k1jrcheoWP8'), ('Bilibili', '<video_id_2>'), ('Osf', '<video_id_3>')]\n",
    "tab_contents = display_videos(video_ids, W=854, H=480)\n",
    "tabs = widgets.Tab()\n",
    "tabs.children = tab_contents\n",
    "for i in range(len(tab_contents)):\n",
    "  tabs.set_title(i, video_ids[i][0])\n",
    "display(tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2155c2a3"
   },
   "source": [
    "---\n",
    "## Section 1.1:  About the ClimateBench dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXBAIVkX35YI"
   },
   "source": [
    "The ClimateBench dataset offers a comprehensive collection of hypothetical climate data derived from sophisticated computer simulations (specifically, the NorESM2 model, available via CIMP6). It includes information on key climate variables such as temperature, precipitation, and diurnal temperature range. These values are collected by running simulations that represent the different Shared Socioeconomic Pathways (SSPs). Each pathway is associated with a different projected emissions profile over time. This data thus provides insights into how these climate variables may change in the future due to different emission scenarios. By utilizing this dataset, researchers can develop predictive models to better understand and anticipate the impacts of climate change, ultimately aiding in the development of effective mitigation strategies. Specifically, this data set is well-formatted for training *machine learning models*, which is exactly what you will do here.\n",
    "\n",
    "A brief overview of the ClimateBench dataset is provided below; for additional details, please refer to the full paper -\n",
    "\n",
    "[ClimateBench v1.0: A Benchmark for Data-Driven Climate Projections](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021MS002954)   \n",
    "\n",
    "---\n",
    "\n",
    "### Spatial Resolution:\n",
    "The simulations are conducted on a grid with a spatial resolution of approximately 2°, allowing for analysis of regional climate patterns and phenomena.\n",
    "\n",
    "---\n",
    "### Variables:\n",
    "The dataset includes four main variables defined for each point on the grid:\n",
    "1. <font color='#1f77b4'>**Temperature (TAS)**</font>: Represents the annual mean surface air temperature.\n",
    "2. <font color='#ff7f0e'>**Diurnal Temperature Range (DTR)**</font>: Reflects the difference between the maximum and minimum temperatures within a day averaged annually.\n",
    "3. <font color='#2ca02c'>**Precipitation (PR)**</font>: Indicates the annual total precipitation.\n",
    "4. <font color='#d62728'>**90th Percentile of Precipitation (PR90)**</font>: Captures extreme precipitation events by identifying the 90th percentile of daily precipitation values.   \n",
    "  \n",
    "\n",
    "---\n",
    "### ScenarioMIP Simulations:\n",
    "The dataset incorporates ScenarioMIP simulations, exploring various future emission pathways under different socio-economic scenarios. Each scenario is defined by a set of annual emissions values over future years. We will look at 5 different scenarios in total here.\n",
    "\n",
    "\n",
    "---\n",
    "### Emissions Inputs:\n",
    "Emissions scenarios are defined according to the following four types of emissions:\n",
    "- <font color='#9467bd'>Carbon dioxide (CO<sub>2</sub>)</font> concentrations.\n",
    "- <font color='#8c564b'>Methane (CH<sub>4</sub>)</font> concentrations.\n",
    "- <font color='#e377c2'>Sulfur dioxide (SO<sub>2</sub>)</font> emissions, a precursor to sulfate aerosols.\n",
    "- <font color='#7f7f7f'>Black carbon (BC)</font> emissions.\n",
    "\n",
    "Note: In the ClimateBench dataset, sulfur dioxide and black carbon emissions are provided as a spatial map over grid locations, but we will just look at global totals here.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Specifications:\n",
    "- Simulation Model: the NorESM2 model is run in its low atmosphere-medium ocean resolution (LM) configuration.\n",
    "- Model Components: Fully coupled earth system including the atmosphere, land, ocean, ice, and biogeochemistry components.\n",
    "- Ensemble Averaging: Target variables are averaged over three ensemble members to mitigate internal variability contributions.\n",
    "\n",
    "---\n",
    "\n",
    "By leveraging the ClimateBench dataset, researchers gain insights into climate dynamics, enabling the development and evaluation of predictive models crucial for understanding and addressing climate change challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngcJmPWr1jDa"
   },
   "source": [
    "<p align='center'><img src='https://github.com/neuromatch/course-content-template/blob/main/tutorials/static/W2D5_Tutorial1_climatebench_Scenario.png' alt='W2D5_Tutorial1_climatebench_Scenario'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptlA4FISvUAE"
   },
   "source": [
    "For simplicity's sake, we'll utilize a **condensed version of the ClimateBench dataset**. As mentioned above, we will be looking at only 5 scenarios ('SSPs', listed above as \"experiments\") and all emissions will be given as global annual averages for the years 2015 to 2050. Furthermore, we will include climate variables for each spatial location (as defined by lattitude and longitude for a restriced region) for the year 2015. The target for our model prediction will be temperature in the year 2050 for each spatial location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3NZv8-yvIQk"
   },
   "source": [
    "## Section 1.2: Load the Dataset (Condensed Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQpZPEgRv7fM"
   },
   "source": [
    "We will use pandas to interface with the data, which is shared in the .csv format. First, let’s load the environmental data into a pandas dataframe and print its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yxb67y_46PEJ"
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "url_Climatebench_train_val = \"https://osf.io/y2pq7/download\"\n",
    "training_data = pd.read_csv(url_Climatebench_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qp_lRZ-lg25t"
   },
   "source": [
    "## Section 1.3: Explore Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUhd7q6m5hLb"
   },
   "source": [
    "Next, we will quickly explore the size of the data, check for missing data, and understand column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4eYzRauJNkW",
    "outputId": "c2a5b92b-0491-41d8-9f9a-a056e448c480"
   },
   "outputs": [],
   "source": [
    "print(training_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wzd_SHoZPRvJ"
   },
   "source": [
    "This tells us we have 3240 rows and 152 columns.\n",
    "\n",
    "Let's look at what these rows and columns mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "64iV0Td5JuA2",
    "outputId": "bace7570-ab44-42af-8b73-4e6fcd2d4070"
   },
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfwBJrAKQ3BN"
   },
   "source": [
    "Each row represents a combination of spatial location and scenario. The scenario can be found in the 'scenario' column while location is given in the 'lat' and 'lon' columns. Climate variables for 2015 are given in the following columns and tas_FINAL represents the temperature in 2050. After these columns, we get the annual global emissions values for each of the 4 emissions types included in ClimateBench, starting in 2015 and ending in 2050."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlF2ljvluDj9"
   },
   "source": [
    "Handle Missing Values (if necessary):\n",
    "\n",
    "We cannot train a machine learning model if there are values missing anywhere in this dataset. Thererfore, we will check for missing values using training_data.isnull().sum(), which sums the number of 'null' or missing values.\n",
    "If missing values exist, we can consider imputation techniques (e.g., fillna, interpolation) based on the nature of the data and the specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_9AgJa4JmlX",
    "outputId": "a9a36fdf-cf40-430e-acaf-3bdf2f1b5396"
   },
   "outputs": [],
   "source": [
    "training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRQAWGi_d-O4"
   },
   "source": [
    "Here, there are no missing values as the sum of all `isnull()` values is zero for all columns. So we are good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfxeLHDH6eYf"
   },
   "source": [
    "## Section 1.4 Visualize the data\n",
    "In this section, we'll utilize visualization techniques to explore the dataset, uncovering underlying patterns and distributions of the variables. Visualizations are instrumental in making informed decisions and conducting comprehensive data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgEvUifS64Xe"
   },
   "source": [
    "**Spatial Distribution of Temperature and Precipitation:**  \n",
    "Plotting the spatial distribution of temperature can reveal geographical patterns and hotspots. We will use the temperature at 2015, the starting point of our simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "I2XxT46r5H3d",
    "outputId": "7bb60f23-589f-4c0a-ed15-3fab01933b7f"
   },
   "outputs": [],
   "source": [
    "# Plot spatial distribution of temperature\n",
    "\n",
    "# Specify the column name for temperature data\n",
    "col_name = 'tas_2015'\n",
    "\n",
    "# Set the size of the figure (plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of latitude and longitude with temperature data as color\n",
    "# 'lon' and 'lat' are columns from the dataset representing longitude and latitude respectively\n",
    "# 'c' parameter specifies the color based on the temperature data\n",
    "# 'cmap' parameter specifies the colormap to use for mapping temperature values to colors\n",
    "# 'alpha' parameter sets the transparency level of the data points\n",
    "plt.scatter(training_data['lon'], training_data['lat'], c=training_data[col_name], cmap='coolwarm', alpha=0.6)\n",
    "\n",
    "# Add colorbar to show temperature legend\n",
    "plt.colorbar(label='Temperature (T)')\n",
    "\n",
    "# Add title to the plot\n",
    "plt.title('Spatial Distribution of Temperature (2015)')\n",
    "\n",
    "# Label x-axis as Longitude\n",
    "plt.xlabel('Longitude')\n",
    "\n",
    "# Label y-axis as Latitude\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Enable grid lines on the plot\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUkZ8AZqTBjV"
   },
   "source": [
    "We can see there are clear variations in 2015 temperatures over space. Note the range of latitude and longitude values. This dataset does not cover the entire globe. In fact, it covers roughly the geographical region represented below:\n",
    "\n",
    "<p align='center'><img src='https://github.com/neuromatch/course-content-template/blob/main/tutorials/static/W2D5_Tutorial1_map.png' alt='W2D5_Tutorial1_map'/></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19cbUYgLUuVL"
   },
   "source": [
    "Now use the same plotting code to make a plot of the spatial distribution of total precipitation: [exercise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JBSGHD1vvt3"
   },
   "source": [
    "### Coding Exercise 1.4:  Plotting Spatial Distribution of Total Precipitation\n",
    "\n",
    "In this exercise, you will complete the code to plot the spatial distribution of total precipitation. Use the provided plotting code as a template and replace the ellipses with appropriate values.\n",
    "\n",
    "Note: Note that you have the necessary libraries already imported (matplotlib.pyplot and pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl36e7ffuP-1"
   },
   "outputs": [],
   "source": [
    "def plot_spatial_distribution(data):\n",
    "    \"\"\"Plot spatial distribution of total precipitation.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing latitude, longitude, and precipitation data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    #################################################\n",
    "    ## TODO for students: details of what they should do ##\n",
    "    # Complete the code to plot the spatial distribution of total precipitation.\n",
    "    # Use the provided plotting code as template and replace the ellipses with appropriate values.\n",
    "    raise NotImplementedError(\"Student exercise: Implement the function according to instructions\")\n",
    "    #################################################\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Fill with the name of appropriate column name to plot the spatial distribution of total precipitation\n",
    "    col_name = ...\n",
    "\n",
    "    # fill in inputs to functions\n",
    "    plt.scatter(..., ..., c=data[col_name], cmap='coolwarm', alpha=0.6)\n",
    "\n",
    "    plt.colorbar(label='Precipitation')\n",
    "    plt.title('Spatial Distribution of Precipitation')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment the code below to test your function\n",
    "\n",
    "#plot_spatial_distribution(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "89-2anbWU3-n",
    "outputId": "1eba150e-8f03-4c59-d712-ea216b3140fd"
   },
   "outputs": [],
   "source": [
    "# to_remove solution\n",
    "\n",
    "def plot_spatial_distribution(data):\n",
    "    \"\"\"Plot spatial distribution of total precipitation.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame containing latitude, longitude, and precipitation data.\n",
    "        col_name (str): Name of the column containing precipitation data.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Fill with the name of appropriate column name to plot the spatial distribution of total precipitation\n",
    "    col_name = 'pr_2015'\n",
    "\n",
    "    # fill in inputs to functions\n",
    "    plt.scatter(data['lon'], data['lat'], c=data[col_name], cmap='coolwarm', alpha=0.6)\n",
    "\n",
    "    plt.colorbar(label='Precipitation')\n",
    "    plt.title('Spatial Distribution of Precipitation')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment the code below to test your function\n",
    "\n",
    "plot_spatial_distribution(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZHZp5wC6nry"
   },
   "source": [
    "**Time Series Plot of Emissions Scenarios:**\n",
    "\n",
    "\n",
    "We'll plot the time series of each of the four emissions scenarios in this dataset (we will get to the fifth one later). Each row in the dataset with the same 'scenario' label has the same emissions values over time. So we will just use the data from the first spatial location for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6FV0EufcO2-v",
    "outputId": "a09259b4-eeff-4ab5-c572-be3201391f9d"
   },
   "outputs": [],
   "source": [
    "# @title Run this cell to plot the Time Series Plot of Emissions Scenarios: { run: \"auto\", display-mode: \"form\" }\n",
    "#Don't worry about understanding this code! It's to setup the plot.\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Extract emissions data for each scenario\n",
    "CO2_data = training_data.filter(regex='CO2_\\d+')\n",
    "SO2_data = training_data.filter(regex='SO2_\\d+')\n",
    "CH4_data = training_data.filter(regex='CH4_\\d+')\n",
    "BC_data = training_data.filter(regex='BC_\\d+')\n",
    "\n",
    "# Define the four scenarios\n",
    "scenarios = ['ssp585',  'ssp370-lowNTCF','ssp126', 'ssp370',]\n",
    "\n",
    "# Create subplots for each emission gas\n",
    "fig, axs = plt.subplots(4, 1, figsize=(8, 15), sharex=True)\n",
    "\n",
    "# Plot emissions data for each emission gas with enhanced styling\n",
    "for i, (data, emission) in enumerate(zip([CO2_data,  CH4_data, SO2_data,BC_data], ['CO2',  'CH4', 'SO2','BC'])):\n",
    "    # Plot each scenario for the current emission gas\n",
    "    for scenario in scenarios:\n",
    "        scenario_data = data[training_data['scenario'] == scenario]\n",
    "        axs[i].plot(range(2015, 2051), scenario_data.mean(axis=0), label=scenario)\n",
    "\n",
    "    # Set ylabel and title for the current emission gas\n",
    "    axs[i].set_ylabel(f'{emission} Emissions', fontsize=12)\n",
    "    axs[i].set_title(f'{emission} Emissions', fontsize=14)\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set common xlabel\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show legends\n",
    "plt.legend()\n",
    "\n",
    "# Remove spines from all subplots\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Customize ticks\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True, linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7VAbXQxYiNP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **Summary**\n",
    "\n",
    "\n",
    "\n",
    "In this tutorial, we acquaint ourselves with the ClimateBench dataset and explore how machine learning contributes to climate analysis. We define the versatility of machine learning and its role in predicting climate variables. By delving into the ClimateBench dataset, we highlight its accessibility in providing climate model data. We emphasize the importance of data visualization and engage in practical exercises to explore the dataset.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8SpKyVbrKzHe",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "                                Congratulations! You have reached the end of the  tutorial.   \n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
